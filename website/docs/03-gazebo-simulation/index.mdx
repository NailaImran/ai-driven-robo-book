---
title: "Module 2: Robot Simulation (Weeks 6-7)"
description: Build and test robots in high-fidelity simulation environments
sidebar_position: 1
---

# Module 2: Robot Simulation (Weeks 6-7)

## ðŸ“š Learning Outcomes

By the end of this module, you will be able to:

1. **Create** realistic simulation environments in Gazebo with physics, sensors, and lighting
2. **Model** robots using URDF (Unified Robot Description Format) with accurate kinematics and dynamics
3. **Integrate** simulated sensors (cameras, LiDAR, IMU) with ROS 2 perception pipelines
4. **Configure** physics engines for accurate contact dynamics and collision detection
5. **Bridge** Gazebo simulations with Unity for photorealistic visualization
6. **Understand** the sim-to-real gap and techniques to minimize it

## ðŸŽ¯ Module Overview

**Duration**: 2 weeks (14 days)
**Prerequisites**: ROS 2 Fundamentals (Module 1), basic Python, URDF/XML syntax

Simulation is **critical** for robotics development:
- **Safety**: Test dangerous scenarios (stair falls, collisions) without risking hardware
- **Speed**: Iterate 10-100x faster than real-world testing
- **Scale**: Test thousands of scenarios in parallel
- **Cost**: Zero cost for robot damage or sensor replacement

This module teaches you to build production-quality simulations that transfer to real robots.

---

## Weekly Breakdown

### **Week 6: Gazebo Fundamentals**

**Topics**:
- Gazebo architecture (client-server, plugins)
- Creating worlds (terrain, lighting, objects)
- URDF robot modeling (links, joints, sensors)
- SDF (Simulation Description Format) vs. URDF
- Physics engines: ODE, Bullet, DART

**Hands-On**:
- Build a warehouse environment
- Model a differential drive mobile robot
- Add RGB camera and 2D LiDAR sensors
- Configure physics parameters (gravity, friction, contact)

**Assessment**: Complete Gazebo world with mobile robot navigating obstacles

### **Week 7: Advanced Simulation & Sim-to-Real**

**Topics**:
- Sensor noise models (Gaussian, ray noise)
- Unity integration for photorealistic rendering
- Gazebo plugins for custom behavior
- Domain randomization for robust policies
- Sim-to-real transfer techniques

**Hands-On**:
- Add sensor noise to camera and LiDAR
- Create custom Gazebo plugin
- Integrate Unity visualization
- Test navigation policy in randomized environments

**Assessment**: Mobile manipulator simulation with realistic sensor noise and Unity visualization

---

## Code Example: URDF Mobile Robot

```xml
<?xml version="1.0"?>
<robot name="simple_robot">
  <!-- Base Link -->
  <link name="base_link">
    <visual>
      <geometry>
        <box size="0.6 0.4 0.2"/>
      </geometry>
      <material name="blue">
        <color rgba="0 0 0.8 1"/>
      </material>
    </visual>
    <collision>
      <geometry>
        <box size="0.6 0.4 0.2"/>
      </geometry>
    </collision>
    <inertial>
      <mass value="10.0"/>
      <inertia ixx="0.133" ixy="0" ixz="0" iyy="0.333" iyz="0" izz="0.433"/>
    </inertial>
  </link>

  <!-- Left Wheel -->
  <link name="left_wheel">
    <visual>
      <geometry>
        <cylinder radius="0.1" length="0.05"/>
      </geometry>
      <material name="black">
        <color rgba="0 0 0 1"/>
      </material>
    </visual>
    <collision>
      <geometry>
        <cylinder radius="0.1" length="0.05"/>
      </geometry>
    </collision>
    <inertial>
      <mass value="1.0"/>
      <inertia ixx="0.0026" ixy="0" ixz="0" iyy="0.0026" iyz="0" izz="0.005"/>
    </inertial>
  </link>

  <joint name="left_wheel_joint" type="continuous">
    <parent link="base_link"/>
    <child link="left_wheel"/>
    <origin xyz="-0.2 0.225 0" rpy="-1.5707 0 0"/>
    <axis xyz="0 0 1"/>
  </joint>

  <!-- Camera Sensor -->
  <link name="camera_link">
    <visual>
      <geometry>
        <box size="0.05 0.05 0.05"/>
      </geometry>
    </visual>
  </link>

  <joint name="camera_joint" type="fixed">
    <parent link="base_link"/>
    <child link="camera_link"/>
    <origin xyz="0.3 0 0.15" rpy="0 0 0"/>
  </joint>

  <gazebo reference="camera_link">
    <sensor name="camera" type="camera">
      <update_rate>30</update_rate>
      <camera>
        <horizontal_fov>1.39626</horizontal_fov>
        <image>
          <width>640</width>
          <height>480</height>
        </image>
        <clip>
          <near>0.1</near>
          <far>100</far>
        </clip>
        <noise>
          <type>gaussian</type>
          <mean>0.0</mean>
          <stddev>0.007</stddev>
        </noise>
      </camera>
      <plugin name="camera_controller" filename="libgazebo_ros_camera.so">
        <ros>
          <namespace>/robot</namespace>
          <remapping>image_raw:=camera/image_raw</remapping>
        </ros>
      </plugin>
    </sensor>
  </gazebo>
</robot>
```

Launch in Gazebo:
```bash
ros2 launch my_robot_description gazebo.launch.py
```

---

## Key Takeaways

âœ… **Gazebo is production-ready** for testing complex behaviors
âœ… **URDF defines robot structure**â€”links (rigid bodies) + joints (connections)
âœ… **Sensors in simulation != reality**â€”always add noise models
âœ… **Physics tuning matters**â€”ODE for speed, Bullet for accuracy
âœ… **Unity for visuals**â€”when you need photorealism or human interaction testing

---

## What's Next?

ðŸ‘‰ **[Module 3: NVIDIA Isaac Platform](/docs/04-nvidia-isaac/)** â€” GPU-accelerated simulation and RL training
