---
title: Project Requirements Checklist
description: Complete checklist for capstone project deliverables
sidebar_position: 2
---

# Project Requirements Checklist

Use this comprehensive checklist to ensure your capstone project meets all requirements before submission.

---

## üìã Core Functionality Checklist

### 1. Autonomous Navigation (20 points)

#### SLAM Implementation
- [ ] Map building works in Gazebo/Isaac Sim
- [ ] Localization accuracy within 10cm
- [ ] SLAM algorithm documented (Cartographer, ORB-SLAM3, etc.)
- [ ] Map saved and can be reloaded

#### Path Planning
- [ ] Global planner generates paths to goal
- [ ] Local planner avoids obstacles
- [ ] Paths are collision-free
- [ ] Replanning works when obstacles move

#### Navigation Performance
- [ ] Successfully navigates 10+ meters
- [ ] Avoids static obstacles (walls, furniture)
- [ ] Avoids dynamic obstacles (moving objects)
- [ ] Reaches goal within 5cm accuracy

#### Testing Scenarios
- [ ] Tested in cluttered environment
- [ ] Tested with narrow passages
- [ ] Tested with moving obstacles
- [ ] Success rate &gt;80% over 10 runs

---

### 2. Vision-Based Manipulation (25 points)

#### Object Detection
- [ ] Detects at least 5 object classes
- [ ] Detection accuracy &gt;85%
- [ ] Runs in real-time (&gt;10 FPS)
- [ ] Model documented (YOLO, Mask R-CNN, etc.)

#### Pose Estimation
- [ ] Estimates 6D pose (position + orientation)
- [ ] Pose estimation error &lt;2cm translation, &lt;5¬∞ rotation
- [ ] Works with RGB-D camera data
- [ ] Handles partial occlusions

#### Grasp Planning
- [ ] Generates valid grasps for detected objects
- [ ] Collision-free arm trajectories
- [ ] Uses inverse kinematics solver
- [ ] Adjusts grasp based on object geometry

#### Manipulation Performance
- [ ] Picks up 3+ different objects
- [ ] Places objects at target locations
- [ ] Grasp success rate &gt;70%
- [ ] No collisions with environment

#### Testing Scenarios
- [ ] Pick from table surface
- [ ] Place in container/shelf
- [ ] Handle different object sizes
- [ ] Tested 10+ pick-place cycles

---

### 3. Bipedal Locomotion (20 points)

#### Walking Controller
- [ ] Stable walking on flat ground
- [ ] Walking speed adjustable (0.1-1.0 m/s)
- [ ] Smooth gait transitions (stop, start, turn)
- [ ] Uses ZMP or similar stability criterion

#### Stair Climbing
- [ ] Climbs at least 3 stairs
- [ ] Stair height 15-20cm (standard)
- [ ] No falls during climb
- [ ] Descends safely

#### Balance Control
- [ ] Maintains balance during arm movements
- [ ] Recovers from small pushes (&lt;5N)
- [ ] IMU-based balance feedback
- [ ] No falls during 5-minute operation

#### Testing Scenarios
- [ ] Walk 5 meters straight
- [ ] Walk in figure-8 pattern
- [ ] Climb stairs while carrying object
- [ ] Stand on one leg for 3 seconds

---

### 4. Conversational Interaction (20 points)

#### Speech Recognition
- [ ] Recognizes voice commands
- [ ] Accuracy &gt;90% in quiet environment
- [ ] Wake word detection ("Hey robot")
- [ ] Uses Whisper or similar ASR

#### Language Understanding
- [ ] LLM integration (GPT-4, LLaMA, etc.)
- [ ] Understands 10+ command types
- [ ] Handles natural language variations
- [ ] Context-aware responses

#### Text-to-Speech
- [ ] Natural-sounding voice output
- [ ] Speaks acknowledgments
- [ ] Error messages clearly communicated
- [ ] Uses modern TTS (ElevenLabs, Azure, Google)

#### Command Set (Minimum 10)
- [ ] "Pick up the [color] [object]"
- [ ] "Move to the [location]"
- [ ] "What do you see?"
- [ ] "Describe your status"
- [ ] "Stop" / "Emergency stop"
- [ ] "Go to the kitchen"
- [ ] "Find the red ball"
- [ ] "Place it on the table"
- [ ] "How many objects do you see?"
- [ ] "What's your battery level?"

#### Testing Scenarios
- [ ] Test all commands individually
- [ ] Test command sequences
- [ ] Test with background noise
- [ ] Record command success rate

---

### 5. System Integration (15 points)

#### Launch System
- [ ] Single launch file starts all nodes
- [ ] Parameters loaded from YAML files
- [ ] Namespaces used correctly
- [ ] Can launch in simulation or hardware mode

#### Error Handling
- [ ] Graceful failures (no crashes)
- [ ] Retry logic for failed operations
- [ ] Logs errors with timestamps
- [ ] Emergency stop works reliably

#### Performance
- [ ] All nodes run in real-time
- [ ] CPU usage &lt;80% on target hardware
- [ ] Memory leaks checked (valgrind)
- [ ] Latency &lt;500ms for commands

#### System Monitoring
- [ ] ROS 2 diagnostics implemented
- [ ] Battery level monitoring
- [ ] Sensor health checks
- [ ] Status published to dashboard

---

## üåü Advanced Features (Bonus Points)

### Multi-Modal Perception (+10 points)
- [ ] Sensor fusion (camera + LiDAR + IMU)
- [ ] Extended Kalman Filter or particle filter
- [ ] Handles sensor failures
- [ ] Improved localization accuracy

### Reinforcement Learning (+15 points)
- [ ] RL policy trained for subtask
- [ ] Training in Isaac Gym or similar
- [ ] Sim-to-real transfer demonstrated
- [ ] Performance comparison with baseline

### Human-Robot Collaboration (+10 points)
- [ ] Hands object to human safely
- [ ] Gesture recognition (MediaPipe, OpenPose)
- [ ] Maintains safe distance from humans
- [ ] Social navigation behaviors

### Dynamic Environments (+10 points)
- [ ] Navigates around moving people
- [ ] Real-time replanning (&lt;1s)
- [ ] Predictive obstacle avoidance
- [ ] Tested with 3+ dynamic obstacles

### Real Hardware Deployment (+20 points)
- [ ] Deployed on physical robot
- [ ] All core features work on hardware
- [ ] Sim-to-real transfer documented
- [ ] Video of hardware demonstration

---

## üì¶ Deliverables Checklist

### 1. Source Code (GitHub Repository)

#### Repository Structure
- [ ] Clear folder organization
- [ ] All ROS 2 packages in `src/` directory
- [ ] Launch files in `launch/` folders
- [ ] Config files in `config/` folders
- [ ] World/model files organized

#### Code Quality
- [ ] Follows ROS 2 naming conventions
- [ ] Python code follows PEP 8
- [ ] C++ code follows Google style guide
- [ ] No commented-out code blocks
- [ ] No hardcoded paths

#### Documentation
- [ ] `README.md` with setup instructions
- [ ] `ARCHITECTURE.md` with system design
- [ ] `LICENSE` file included
- [ ] Dependencies listed in `requirements.txt`
- [ ] All packages have `package.xml`

#### Version Control
- [ ] Meaningful commit messages
- [ ] Feature branches (not all on main)
- [ ] .gitignore configured properly
- [ ] No large binary files committed
- [ ] Build artifacts excluded

#### README.md Required Sections
- [ ] Project title and description
- [ ] Team members
- [ ] Hardware/software requirements
- [ ] Installation instructions
- [ ] Usage instructions
- [ ] Launch file examples
- [ ] Demo video link
- [ ] Known issues
- [ ] License information

---

### 2. Demo Video (3-5 minutes)

#### Content Requirements
- [ ] Introduction with names/title
- [ ] System architecture overview
- [ ] Navigation demonstration
- [ ] Object detection and grasping
- [ ] Locomotion (walking + stairs)
- [ ] Voice command interaction
- [ ] Advanced features (if applicable)
- [ ] Reflections/learnings

#### Technical Quality
- [ ] 1080p resolution minimum
- [ ] Clear audio (no background noise)
- [ ] Smooth transitions between clips
- [ ] Text overlays for clarity
- [ ] Picture-in-picture views
- [ ] Uploaded to YouTube or Vimeo
- [ ] Link works and is accessible

#### Presentation
- [ ] Professional narration
- [ ] Explains what's happening
- [ ] Highlights key features
- [ ] Shows real-time execution
- [ ] Demonstrates failure recovery
- [ ] Credits used libraries/tools

---

### 3. Technical Report (5-10 pages)

#### Abstract (0.5 pages)
- [ ] Problem statement
- [ ] Approach summary
- [ ] Key results
- [ ] Main contributions

#### Introduction (1 page)
- [ ] Motivation for project
- [ ] Background on humanoid robotics
- [ ] Related work (2-3 citations)
- [ ] Paper organization

#### System Architecture (2-3 pages)
- [ ] Block diagram of system
- [ ] ROS 2 node graph (rqt_graph)
- [ ] Component descriptions
- [ ] Data flow explained
- [ ] Hardware/software stack
- [ ] Design decisions justified

#### Implementation Details (2-3 pages)
- [ ] Navigation: Algorithm, parameters
- [ ] Manipulation: Detection model, grasp planner
- [ ] Locomotion: Controller type, gait parameters
- [ ] Conversation: LLM choice, speech pipeline
- [ ] Code snippets for key algorithms
- [ ] Figures/diagrams for clarity

#### Experimental Results (1-2 pages)
- [ ] Quantitative metrics table
- [ ] Success rates for each capability
- [ ] Performance graphs (latency, accuracy)
- [ ] Comparison to baseline
- [ ] Failure analysis with examples
- [ ] Statistical significance (if applicable)

#### Conclusion & Future Work (0.5 pages)
- [ ] Summary of achievements
- [ ] Challenges overcome
- [ ] Lessons learned
- [ ] Future improvements
- [ ] Broader impact

#### References
- [ ] At least 5 citations
- [ ] Proper IEEE/ACM format
- [ ] Mix of papers and documentation
- [ ] All citations used in text

#### Formatting
- [ ] IEEE or ACM template used
- [ ] Consistent font and spacing
- [ ] Page numbers included
- [ ] Figures numbered and captioned
- [ ] Tables formatted properly
- [ ] PDF format
- [ ] No spelling/grammar errors

---

## ‚úÖ Pre-Submission Checklist

### Testing
- [ ] Code runs without errors on clean system
- [ ] All dependencies installable
- [ ] Launch files tested
- [ ] Demo recorded successfully
- [ ] Report proofread
- [ ] All links work

### Code Cleanup
- [ ] Removed debug print statements
- [ ] Removed unused imports
- [ ] Removed TODO comments
- [ ] Updated comments to match code
- [ ] Ran code formatter (black, clang-format)
- [ ] Fixed all linter warnings

### Repository
- [ ] README updated
- [ ] Demo video link added
- [ ] All files committed
- [ ] Repo is public or access granted
- [ ] No sensitive data (API keys, passwords)

### Documentation
- [ ] All sections complete
- [ ] Figures have captions
- [ ] References formatted correctly
- [ ] PDF generated successfully
- [ ] File size &lt;10MB

---

## üìä Grading Breakdown

| Component | Points | Your Score |
|-----------|--------|------------|
| Navigation | 20 | ___ / 20 |
| Manipulation | 25 | ___ / 25 |
| Locomotion | 20 | ___ / 20 |
| Conversation | 20 | ___ / 20 |
| Integration | 15 | ___ / 15 |
| Code Quality | 10 | ___ / 10 |
| Report | 10 | ___ / 10 |
| Demo Video | 10 | ___ / 10 |
| **Base Total** | **130** | **___ / 130** |
| Bonus Features | +30 max | +___ |
| **Final Score** | **100%** | **___%** |

---

## üöÄ Tips for Success

### Week 1 (Planning)
1. **Start early** - Don't wait until the last week
2. **Use existing packages** - Don't reinvent the wheel
3. **Test incrementally** - Get each module working before integration
4. **Ask for help** - Use office hours and discussion forums

### Week 2 (Implementation)
1. **Commit often** - Version control is your friend
2. **Document as you go** - Don't leave it for the end
3. **Record test videos** - Useful for debugging and final demo
4. **Handle edge cases** - What happens when detection fails?

### Week 3 (Documentation)
1. **Polish the demo** - Edit out long pauses
2. **Write clearly** - Assume reader is smart but unfamiliar
3. **Include visuals** - A picture is worth 1000 words
4. **Proofread everything** - Typos hurt professionalism

### Common Pitfalls to Avoid
- ‚ùå Hardcoding paths (`/home/yourname/...`)
- ‚ùå Not testing on clean system
- ‚ùå Waiting until last minute
- ‚ùå Ignoring error messages
- ‚ùå Skipping code documentation
- ‚ùå Poor video quality
- ‚ùå Missing citations in report

---

## üìö Resources

**ROS 2 Best Practices**:
- [ROS 2 Design Guide](https://design.ros2.org/)
- [Quality Declaration](https://github.com/ros-infrastructure/rep/blob/master/rep-2004.rst)

**Writing Technical Reports**:
- [IEEE Paper Template](https://www.ieee.org/conferences/publishing/templates.html)
- [ACM Paper Template](https://www.acm.org/publications/proceedings-template)

**Video Production**:
- OBS Studio (screen recording)
- DaVinci Resolve (editing, free)
- Audacity (audio editing)

---

## Need Help?

**Stuck on a requirement?**
- Review corresponding week's material
- Check GitHub issues in reference implementations
- Post on course forum
- Attend office hours

**Technical issues?**
- Search ROS Answers
- Check package documentation
- Enable verbose logging for debugging

---

**Ready to build? Head to [Autonomous Humanoid Guide](/docs/09-capstone/autonomous-humanoid.mdx)** ü§ñ
